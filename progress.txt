## Codebase Patterns
- Backend: FastAPI in backend/main.py, Python venv at ./venv
- Frontend: Next.js + Tailwind in frontend/, port 4321
- DSPy RLM: dspy.RLM with Gemini 3 Flash, depth=1
- WebSocket for real-time iteration streaming
- All styling via Tailwind CSS
- GOOGLE_API_KEY in .env at project root
---

## 2026-02-14 01:50 - US-001: Project scaffolding and dependency setup
- Created Python venv with dspy, fastapi, uvicorn, pypdf, python-docx, websockets, python-dotenv
- Created FastAPI backend at backend/main.py with /health endpoint and CORS for localhost:4321
- Created Next.js + Tailwind frontend at frontend/ configured for port 4321
- Created .env with GOOGLE_API_KEY, start scripts, .gitignore
- **Learnings for future iterations:**
  - Backend loads .env from parent dir via python-dotenv
  - Frontend runs on port 4321, backend on 8000
  - Use venv/bin/python for all Python commands
  - Frontend build: `cd frontend && npm run build`
  - Backend check: `venv/bin/python -m py_compile backend/main.py`
---

## 2026-02-14 01:55 - US-002: Document upload and text extraction API
- Added POST /api/upload with PDF/DOCX/TXT extraction
- Added GET /api/documents, GET /api/documents/{id}, DELETE /api/documents/{id}
- In-memory storage with uuid4 keys
- **Learnings for future iterations:**
  - documents dict stores full text but list endpoint only returns id/filename/text_length
  - Upload field name is 'file'
  - File type detection by extension
---

## 2026-02-14 01:55 - US-003: DSPy RLM core query pipeline
- Created backend/rlm_pipeline.py with DocumentQA signature, configure_dspy(), query_document()
- Added POST /api/query endpoint to main.py
- Token tracking via LM history, sub-LLM call counting from trajectory
- **Learnings for future iterations:**
  - dspy.RLM returns Prediction with .trajectory (list of dicts) and .answer
  - configure_dspy() must be called before creating RLM instance
  - Token tracking uses lm.history - may need refinement when testing with real API
  - Import in main.py: `from rlm_pipeline import query_document` (relative, since uvicorn runs from backend/)
---

## 2026-02-14 01:58 - US-004: WebSocket streaming endpoint
- Created backend/ws_handler.py with handle_query_ws()
- WebSocket at /ws/query: accepts {document_id, question}, streams iterations, sends result
- Uses ThreadPoolExecutor to run sync RLM in async context
- Trajectory replay with 0.1s delay for UI animation
- **Learnings for future iterations:**
  - WebSocket events: status, iteration, result, error
  - Frontend should connect to ws://localhost:8000/ws/query
  - Each iteration event has: {iteration, reasoning, code, output}
  - Result event has: {answer, metrics: {tokens, time_s, iterations, depth, sub_llm_calls}}
---

## 2026-02-14 02:02 - US-005: Frontend document upload UI
- Created frontend/app/components/DocumentUpload.tsx with drag-drop, file list, selection, delete
- Created frontend/app/lib/api.ts with uploadDocument, listDocuments, deleteDocument helpers
- Updated page.tsx to two-panel layout with header + sidebar + main area
- **Learnings for future iterations:**
  - API base: http://localhost:8000
  - DocumentInfo interface: {id, filename, text_length, preview?}
  - Components use "use client" directive
  - onDocumentSelect callback pattern for cross-component communication
  - All styling via Tailwind, dark zinc theme
---
